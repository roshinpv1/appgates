
# Local LLM Configuration (currently active)
LOCAL_LLM_URL="http://localhost:1234/v1"
LOCAL_LLM_API_KEY="local-llm-key"
#LOCAL_MODEL="meta-llama-3.1-8b-instruct"
LOCAL_MODEL=deepseek-r1-distill-qwen-7b
LOCAL_LLM_TEMPERATURE=0.5
LOCAL_LLM_MAX_TOKENS=-1

CODEGATES_LLM_REQUEST_TIMEOUT=1000


